The Mask-RCNN model used has been taken and modified as per use from the following github repository:
https://github.com/matterport/Mask_RCNN

Solution file : nucleus segmentation.ipynb
Model Weights : mask_rcnn_nucleus_seg.h5

Approach:--->

1> Necessary imports are made and paths are set for reading data and saving weights.

2> The configuration of the whole segmentation model is specified. We override some default 
configurations of the imported model to suit the needs of our machine. This is done because at
given time there are many factors or hyperparameters affecting segmentation tasks. We compile all
these hyperparameters into a single function and set the desired configuration.

3> Data is loaded and a class defining necessary functions to load images and masks is written. This
again is simply overriding the imported functions to suit our needs. We then visualize some of the
data along with the corresponding segmentation mask.

4> The model is defined and instead of training the model from scratch, we initialise weights as per 
some previously trained data like MS COCO dataset.

5> The backbone layers are freezed and the latter layers are trained to suit our dataset. After the
training the model weights are saved to be used in inference.

6> The model is tested on validation set that we kept out earlier to see how it performs as well as 
visualize the output of segmentation.

7> The model is tested on test images. mAP for training and validation set is calculated.


*NOTE: As per question statement, it was required to plot mAP of testing and training data but I 
couldn't figure out how do we calculate mAP for testing data if we do not have the corresponding 
masks or RoIs for the testing images.